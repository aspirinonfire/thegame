using Microsoft.ML;
using System.Text.Json.Serialization;

namespace TheGame.PlateTrainer;

public sealed record CvFoldScores()
{
  /// <summary>
  /// 1-based index of the correct class/label; must satisfy 1 <= Label <= Score.Length.
  /// </summary>
  public uint Label { get; set; }

  /// <summary>
  /// Per-class scores generated by the model during prediction in fixed order.
  /// Score[i] corresponds to class (i+1)
  /// </summary>
  public float[] Score { get; set; } = [];
}

public sealed record SetMetrics(double MicroAccuracy,
  double MacroAccuracy,
  double TopKAccuracy,
  double LogLoss,
  double Ndcg,
  int K,
  [property:JsonIgnore] Microsoft.ML.Data.ConfusionMatrix ConfusionMatrix,
  [property: JsonIgnore] IReadOnlyDictionary<string, double> PerClassLogLoss)
{
  public static SetMetrics FromAverage(IEnumerable<SetMetrics> metrics) => new SetMetrics(
    MicroAccuracy: metrics.Average(f => f.MicroAccuracy),
    MacroAccuracy: metrics.Average(f => f.MacroAccuracy),
    TopKAccuracy: metrics.Average(f => f.TopKAccuracy),
    LogLoss: metrics.Average(f => f.LogLoss),
    Ndcg: metrics.Average(f => f.Ndcg),
    K: metrics.Select(m => m.K).FirstOrDefault(),
    null!,
    null!);

  public void Print(string prefix = "")
  {
    if (!string.IsNullOrEmpty(prefix))
    {
      prefix = $"{prefix} ";
    }
    
    Console.WriteLine($"{prefix}MicroAccuracy: {MicroAccuracy:0.000}");
    Console.WriteLine($"{prefix}MacroAccuracy: {MacroAccuracy:0.000}");
    Console.WriteLine($"{prefix}Top-{K} accuracy: {TopKAccuracy:0.000}");
    Console.WriteLine($"{prefix}NDCG({K}): {Ndcg:0.000}");
    Console.WriteLine($"{prefix}LogLoss: {LogLoss:0.000}");
  }
}

public sealed class ModelEvaluationService(MLContext ml)
{
  public static double CalculateNdcg(IEnumerable<CvFoldScores> rows, int k = 10) =>
    rows.Select(r =>
    {
      var labelIndex = Math.Max(0, (int)r.Label - 1);
      var trueScore = r.Score[labelIndex];
      var rank = 1 + r.Score.Count(s => s > trueScore);
      if (rank > k)
      {
        return 0.0;
      }
      return Math.Log(2.0) / Math.Log(rank + 1.0);
    })
    .DefaultIfEmpty(0.0)
    .Average();

  public SetMetrics CalculateMetricsForSet(IDataView scored, string[] labels, int k = 10)
  {
    var metrics = ml.MulticlassClassification.Evaluate(scored,
      labelColumnName: nameof(PlateRow.Label),
      topKPredictionCount: k);

    var rows = ml.Data
      .CreateEnumerable<CvFoldScores>(scored,
        reuseRowObject: false,
        ignoreMissingColumns: false);

    var perClassLl = metrics.PerClassLogLoss
      .Select((loss, idx) => new
      {
        loss,
        label = labels[idx]
      })
      .ToDictionary(x => x.label, x => x.loss);

    return new
    (
      metrics.MicroAccuracy,
      metrics.MacroAccuracy,
      metrics.TopKAccuracy,
      metrics.LogLoss,
      Ndcg: CalculateNdcg(rows, k),
      k,
      metrics.ConfusionMatrix,
      PerClassLogLoss: perClassLl.AsReadOnly()
    );
  }

  public SetMetrics EvaluateHoldOutSet(ITransformer model, string[] labels, IDataView holdOutDataView)
  {
    Console.WriteLine("----- Evaluating the trained model...");

    var scored = model.Transform(holdOutDataView);

    var metrics = CalculateMetricsForSet(scored, labels);

    metrics.Print("Holdout");

    var perClassLogLoss = metrics.PerClassLogLoss
      .OrderBy(pcll => pcll.Value);

    Console.WriteLine("Per Class Log Loss:");
    foreach (var classLogLoss in perClassLogLoss)
    {
      Console.WriteLine($"{classLogLoss.Key}: {classLogLoss.Value:0.000}");
    }

    return metrics;
  }

  public void OutputConfusionMatrix(string[] labels, SetMetrics metrics)
  {
    Console.WriteLine("Confusion Matrix (rows=actual, cols=predicted):");

    Console.Write("actual\\pred");
    foreach (var name in labels)
    {
      Console.Write($"\t{name}");
    }
    Console.WriteLine();

    for (int actualIndex = 0; actualIndex < metrics.ConfusionMatrix.NumberOfClasses; actualIndex++)
    {
      Console.Write(labels[actualIndex]);
      for (int predictedIndex = 0; predictedIndex < metrics.ConfusionMatrix.NumberOfClasses; predictedIndex++)
      {
        // Counts are integers represented as doubles; print as integers.
        var count = (long)metrics.ConfusionMatrix.Counts[actualIndex][predictedIndex];
        Console.Write($"\t{count}");
      }
      Console.WriteLine();
    }
  }
}
